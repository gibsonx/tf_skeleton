{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibsonx/tf_skeleton/blob/master/20241207_hm_regression_prelim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Ba4JK4qtx3y"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "import keras.backend as K\n",
        "import keras.utils\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import Activation, Add, Conv2D, Conv2DTranspose, concatenate, Cropping2D, MaxPooling2D, Reshape, UpSampling2D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import os.path\n",
        "from typing import Any, Callable, List, Optional, Tuple\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os, json, cv2, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.bool = np.bool_\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential,Model\n",
        "\n",
        "from keras.layers import (\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Conv2D,\n",
        "    LeakyReLU,\n",
        "    BatchNormalization,\n",
        "    MaxPool2D,\n",
        "    GlobalAveragePooling2D,\n",
        ")\n",
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia\n",
        "import imageio\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications.densenet import DenseNet121,DenseNet169,DenseNet201\n",
        "from imgaug.augmentables.kps import Keypoint, KeypointsOnImage\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5x0NOxYugzb",
        "outputId": "dfb47abb-bb0f-47a1-b004-fcddf8a245bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X-Ray Dataset loader"
      ],
      "metadata": {
        "id": "c0JegdwQH9iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataframeMaker():\n",
        "\n",
        "  def __init__(self,img_path,annotations_file, img_height, img_width):\n",
        "      self.img_path = img_path\n",
        "      self.coco = COCO(annotations_file)\n",
        "      self.imgIds = self.coco.getImgIds()\n",
        "      self.dataframe = None\n",
        "      self.__coco_build__()\n",
        "      self.img_height = img_height\n",
        "      self.img_width = img_width\n",
        "      if self.img_width and self.img_height:\n",
        "          self.resize_dataset()\n",
        "          print (\"image size has been set to %d x %d\" % (self.img_height, self.img_width))\n",
        "      else:\n",
        "          print (\"image keeps as original size\")\n",
        "\n",
        "  def __coco_build__(self):\n",
        "      \"\"\"\n",
        "      read annotation and build dataframe\n",
        "      :return:\n",
        "      \"\"\"\n",
        "      kps_metrix = []\n",
        "\n",
        "      for id in self.imgIds:\n",
        "\n",
        "        # load a image\n",
        "        img = self.coco.loadImgs(id)[0]\n",
        "        imgPath = img['file_name']\n",
        "\n",
        "        ann=self.coco.loadAnns(self.coco.getAnnIds(imgIds=img['id']))\n",
        "\n",
        "        keypoints_original = [[list(a) for a in zip(*[iter(ann[0]['keypoints'])]*3)]]\n",
        "\n",
        "        kps_row = []\n",
        "        for kp in keypoints_original:\n",
        "            for el in kp:\n",
        "                kps_row.extend(el[0:2])\n",
        "        kps_row.append(imgPath)\n",
        "\n",
        "        kps_metrix.append(kps_row)\n",
        "\n",
        "      df = pd.DataFrame(kps_metrix)\n",
        "\n",
        "      self.dataframe = df\n",
        "\n",
        "  def resize_dataset(self):\n",
        "    \"\"\"\n",
        "    :param img_height:\n",
        "    :param img_width:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    ts_kps_metrix = []\n",
        "    ts_image_list = []\n",
        "\n",
        "    for index, row in self.dataframe.iterrows():\n",
        "\n",
        "\n",
        "      image = row[-1:].item()\n",
        "      fullImgPath = os.path.join(self.img_path,image)\n",
        "      open_cv_image = np.array(Image.open(fullImgPath).convert('RGB'))\n",
        "      # print(\"shpae:\",open_cv_image.shape)\n",
        "\n",
        "      annotations = row[:32]\n",
        "      converted_keypoints = [list(a) for a in zip(*[iter(annotations)]*2)]\n",
        "\n",
        "      kps = [Keypoint(x=coodination[0], y=coodination[1]) for coodination in converted_keypoints]\n",
        "      kpsoi = KeypointsOnImage(kps, shape=open_cv_image.shape)\n",
        "\n",
        "      ia.seed(1)\n",
        "\n",
        "      seq = iaa.Sequential([\n",
        "          iaa.Crop(px=(32, 32, 32, 32)),\n",
        "          iaa.Resize({\"height\": self.img_height , \"width\": self.img_width}),\n",
        "          # iaa.CropToFixedSize(height=self.img_width, width=self.img_width, position=\"center-top\")\n",
        "      ])\n",
        "\n",
        "      image_aug, kpsoi_aug = seq(image=open_cv_image, keypoints=kpsoi)\n",
        "\n",
        "      ts_kps_row = []\n",
        "\n",
        "      for i in range(len(kpsoi_aug.keypoints)):\n",
        "          after = kpsoi_aug.keypoints[i]\n",
        "          ts_kps_row.extend([after.x,after.y])\n",
        "\n",
        "      ts_kps_metrix.append(ts_kps_row)\n",
        "      ts_image_list.append(image_aug)\n",
        "\n",
        "    df = pd.DataFrame(ts_kps_metrix)\n",
        "\n",
        "    df['image'] = ts_image_list\n",
        "\n",
        "    self.dataframe = df"
      ],
      "metadata": {
        "id": "aH2Nx3PJp3zW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height = 457\n",
        "width = 256\n",
        "num_kps = 16\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Dataset/facial-keypoints-detection/\"\n",
        "\n",
        "train_img_dir=\"/content/drive/MyDrive/Dataset/aspine202030604/images\"\n",
        "train_annotations_file=\"/content/drive/MyDrive/Dataset/aspine202030604/annotations/person_keypoints_Train.json\"\n",
        "\n",
        "val_img_dir=\"/content/drive/MyDrive/Dataset/aspine20230930/image_val\"\n",
        "val_annotations_file=\"/content/drive/MyDrive/Dataset/aspine20230930/annotations/person_keypoints_Validation.json\"\n",
        "\n",
        "\n",
        "val_df = DataframeMaker(val_img_dir,val_annotations_file,height,width)\n",
        "train_df = DataframeMaker(train_img_dir,train_annotations_file,height,width)"
      ],
      "metadata": {
        "id": "Wfj_UgllvGwG",
        "outputId": "602786a8-c781-4d70-fe4f-b239999fa004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.04s)\n",
            "creating index...\n",
            "index created!\n",
            "image size has been set to 457 x 256\n",
            "loading annotations into memory...\n",
            "Done (t=1.04s)\n",
            "creating index...\n",
            "index created!\n",
            "image size has been set to 457 x 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X-Ray DataGenerator"
      ],
      "metadata": {
        "id": "onS7VSf3IHGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "\n",
        "  def __init__(self, dataframe, batch_size, arguement = False):\n",
        "      self.df = dataframe\n",
        "      self.batch_size = batch_size\n",
        "      self.argument = arguement\n",
        "\n",
        "  def __len__(self):\n",
        "      return math.ceil(len(self.df) / self.batch_size)\n",
        "\n",
        "  # check if transformed point is located within image boundaries\n",
        "  def _checkBoundaries(self, p):\n",
        "\n",
        "      # x dimension\n",
        "      if p[0] < 0:\n",
        "          px = 0\n",
        "      elif p[0] > self.target_size[0]:\n",
        "          px = self.target_size[0]\n",
        "      else:\n",
        "          px = p[0]\n",
        "\n",
        "      # y dimension\n",
        "      if p[1] < 0:\n",
        "          py = 0\n",
        "      elif p[1] > self.target_size[1]:\n",
        "          py = self.target_size[1]\n",
        "      else:\n",
        "          py = p[1]\n",
        "\n",
        "      return (int(px), int(py))\n",
        "\n",
        "  # apply gaussian kernel to image\n",
        "  def _gaussian(self, xL, yL, sigma, H, W):\n",
        "\n",
        "      channel = [math.exp(-((c - xL) ** 2 + (r - yL) ** 2) / (2 * sigma ** 2)) for r in range(H) for c in range(W)]\n",
        "      channel = np.array(channel, dtype=np.float32)\n",
        "      channel = np.reshape(channel, newshape=(H, W))\n",
        "\n",
        "      return channel\n",
        "\n",
        "  # convert original image to heatmap\n",
        "  def _convertToHM(self, img, keypoints, sigma=5):\n",
        "\n",
        "      H = img.shape[0]\n",
        "      W = img.shape[1]\n",
        "      nKeypoints = len(keypoints)\n",
        "\n",
        "      img_hm = np.zeros(shape=(H, W, nKeypoints // 2), dtype=np.float32)\n",
        "\n",
        "      for i in range(0, nKeypoints // 2):\n",
        "          x = keypoints[i * 2]\n",
        "          y = keypoints[1 + 2 * i]\n",
        "\n",
        "          channel_hm = self._gaussian(x, y, sigma, H, W)\n",
        "\n",
        "          img_hm[:, :, i] = channel_hm\n",
        "\n",
        "      img_hm = np.reshape(img_hm, newshape=(img_hm.shape[0]*img_hm.shape[1]*nKeypoints // 2, 1))\n",
        "\n",
        "      return img_hm\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      low = idx * self.batch_size\n",
        "      # Cap upper bound at array length; the last batch may be smaller\n",
        "      # if the total number of items is not a multiple of batch size.\n",
        "      high = min(low + self.batch_size, len(self.df))\n",
        "      # images = self.df.loc[low:high,'image']\n",
        "      # annotations = self.df.loc[low:high,:31]\n",
        "      current_batch = self.df.iloc[low:high]\n",
        "\n",
        "      x = [] # images\n",
        "      y = [] # masks\n",
        "      z = [] # keypoinsts\n",
        "\n",
        "      for index, row in current_batch.iterrows():\n",
        "\n",
        "        img = row['image']\n",
        "        img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
        "        img = np.float32(img) / 255\n",
        "\n",
        "        keypoints = row[:32]\n",
        "        img_hm = self._convertToHM(img, keypoints)\n",
        "\n",
        "        x.append(img)\n",
        "        y.append(img_hm)\n",
        "        z.append(keypoints)\n",
        "\n",
        "      if self.argument:\n",
        "         return self.data_arguement(x, z)\n",
        "      else:\n",
        "         return np.array(x, dtype=np.float32), np.array(y, dtype=np.float32)\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "      print(\"shuffle\")\n",
        "      self.df = self.df.sample(frac=1, random_state=41).reset_index(drop=True)\n",
        "\n",
        "  def data_arguement(self, images, annotations):\n",
        "\n",
        "      ia.seed(3)\n",
        "      seq = iaa.Sequential([\n",
        "            iaa.Sometimes(\n",
        "              0.5,\n",
        "              iaa.SomeOf((1, 3), [\n",
        "              iaa.Affine(\n",
        "                  rotate=(-8,8)\n",
        "                  ),\n",
        "              iaa.LinearContrast((0.4, 1.2)),\n",
        "              # iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
        "              ])\n",
        "            )\n",
        "          ])\n",
        "\n",
        "      images_aug, points_aug = seq(images=images, keypoints=self.kpslist_to_tuple(annotations))\n",
        "      kps_list = self.kpstuple_to_list(points_aug)\n",
        "\n",
        "      x = [] # images\n",
        "      y = [] # masks\n",
        "\n",
        "      for i in range(len(images_aug)):\n",
        "        img_hm = self._convertToHM(images_aug[i], kps_list[i])\n",
        "        x.append(images_aug[i])\n",
        "        y.append(img_hm)\n",
        "\n",
        "      return np.array(x, dtype=np.float32), np.array(y, dtype=np.float32)\n",
        "\n",
        "  def kpslist_to_tuple(self,annotations):\n",
        "      kpstuple = []\n",
        "\n",
        "      for row in annotations:\n",
        "        converted_keypoints = [list(a) for a in zip(*[iter(row)]*2)]\n",
        "        kps = [Keypoint(x=coodination[0], y=coodination[1]) for coodination in converted_keypoints]\n",
        "        kpstuple.append(kps)\n",
        "\n",
        "      return kpstuple\n",
        "\n",
        "  def kpstuple_to_list(self,kps_tuple):\n",
        "      kpslist = []\n",
        "\n",
        "      for kpsoi in kps_tuple:\n",
        "          ts_kps_row = []\n",
        "          for i in range(len(kpsoi)):\n",
        "              # print(kpsoi_aug[i].is_out_of_image(image=images_aug[i]))\n",
        "              ts_kps_row.extend([kpsoi[i].x,kpsoi[i].y])\n",
        "          kpslist.append(ts_kps_row)\n",
        "\n",
        "      return kpslist"
      ],
      "metadata": {
        "id": "M87ZaqZ2p9Ar"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCwm6azztx31"
      },
      "source": [
        "## Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=8\n",
        "\n",
        "val_gen = DataGenerator(val_df.dataframe,batch_size,False)\n",
        "train_gen = DataGenerator(train_df.dataframe,batch_size,True)"
      ],
      "metadata": {
        "id": "iYlekRIb0t6I"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs, train_masks = train_gen[0]\n",
        "val_imgs, val_masks = val_gen[0]"
      ],
      "metadata": {
        "id": "a5EN_gBloFHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# show xray makes"
      ],
      "metadata": {
        "id": "8aAa4MQOiCXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_xray_masks(height, width, num_kps, batch_imgs, batch_gt_masks, nrows, ncols, include_preds= False, predictions=None):\n",
        "\n",
        "    if not include_preds:\n",
        "        nrows -= 1\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
        "\n",
        "    r = -1\n",
        "\n",
        "    for c in range(ncols):\n",
        "\n",
        "        # original image\n",
        "        img = batch_imgs[c]\n",
        "        img = np.reshape(img, newshape=(height, width))\n",
        "        img = np.stack([img,img,img], axis=-1)\n",
        "\n",
        "        # ground-truth mask\n",
        "        gt_mask = batch_gt_masks[c]\n",
        "        gt_mask = np.reshape(gt_mask, newshape=(height, width, num_kps))\n",
        "        gt_mask = np.sum(gt_mask, axis=-1)\n",
        "\n",
        "        axes[0, c].imshow(img)\n",
        "        axes[1, c].imshow(gt_mask)\n",
        "\n",
        "        # prediction mask\n",
        "        if include_preds:\n",
        "            pred_mask = predictions[c]\n",
        "            pred_mask = np.reshape(pred_mask, newshape=(height, width, num_kps))\n",
        "            pred_mask = np.sum(pred_mask, axis=-1)\n",
        "            axes[2, c].imshow(pred_mask)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2tgA_8luiBmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize Train Dataset"
      ],
      "metadata": {
        "id": "GguaWRblqK5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_xray_masks(height, width, num_kps, train_imgs[0:4], train_masks[0:4], nrows=3, ncols=4)"
      ],
      "metadata": {
        "id": "KBDQAECPi8Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Validation Dataset"
      ],
      "metadata": {
        "id": "KltIVftrvjrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_xray_masks(width, width, num_kps, val_imgs[0:4], val_masks[0:4], nrows=3, ncols=4)"
      ],
      "metadata": {
        "id": "-LDMU3v4vpQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04YU5Hj5tx31"
      },
      "source": [
        "### UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quEAr55ktx31"
      },
      "outputs": [],
      "source": [
        "def UNET(input_shape):\n",
        "    def downsample_block(x, block_num, n_filters, pooling_on=True):\n",
        "\n",
        "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "                   name=\"Block\" + str(block_num) + \"_Conv1\")(x)\n",
        "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "                   name=\"Block\" + str(block_num) + \"_Conv2\")(x)\n",
        "        skip = x\n",
        "\n",
        "        if pooling_on is True:\n",
        "            x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', name=\"Block\" + str(block_num) + \"_Pool1\")(x)\n",
        "\n",
        "        return x, skip\n",
        "\n",
        "    def upsample_block(x, skip, block_num, n_filters):\n",
        "\n",
        "        # if x.shape[1] * 2 != skip.shape[1]:\n",
        "            # dw = int(skip.shape[1] - (x.shape[1] * 2)) // 2\n",
        "            # skip = Cropping2D(cropping=((dw, dw), (dw, dw)), name=\"Block\" + str(block_num) + \"_Crop1\")(skip)\n",
        "\n",
        "        x = Conv2DTranspose(n_filters, kernel_size=(2, 2), strides=2, padding='valid', activation='relu',\n",
        "                            name=\"Block\" + str(block_num) + \"_ConvT1\")(x)\n",
        "        x = concatenate([x, skip], axis=-1, name=\"Block\" + str(block_num) + \"_Concat1\")\n",
        "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "                   name=\"Block\" + str(block_num) + \"_Conv1\")(x)\n",
        "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
        "                   name=\"Block\" + str(block_num) + \"_Conv2\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    input = Input(input_shape, name=\"Input\")\n",
        "\n",
        "    # downsampling\n",
        "    x, skip1 = downsample_block(input, 1, 64)\n",
        "    x, skip2 = downsample_block(x, 2, 128)\n",
        "    x, skip3 = downsample_block(x, 3, 256)\n",
        "    x, skip4 = downsample_block(x, 4, 512)\n",
        "    x, _ = downsample_block(x, 5, 1024, pooling_on=False)\n",
        "\n",
        "\n",
        "    # upsampling\n",
        "    x = upsample_block(x, skip4, 6, 512)\n",
        "    x = upsample_block(x, skip3, 7, 256)\n",
        "    x = upsample_block(x, skip2, 8, 128)\n",
        "    x = upsample_block(x, skip1, 9, 64)\n",
        "\n",
        "    output = Conv2D(16, kernel_size=(1, 1), strides=1, padding='valid', activation='linear', name=\"output\")(x)\n",
        "    output = Reshape(target_shape=(input_shape[0]*input_shape[1]*16,1))(output)\n",
        "\n",
        "    model = Model(inputs=input, outputs=output, name=\"Output\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "unet = UNET(input_shape=(width, width, 1))\n",
        "print(unet.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3njAz_vYtx32"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suPT2CZ4tx32"
      },
      "outputs": [],
      "source": [
        "def jaccard(ytrue, ypred, smooth=1e-5):\n",
        "\n",
        "    intersection = K.sum(K.abs(ytrue*ypred), axis=-1)\n",
        "    union = K.sum(K.abs(ytrue)+K.abs(ypred), axis=-1)\n",
        "    jac = (intersection + smooth) / (union-intersection+smooth)\n",
        "\n",
        "    return K.mean(jac)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw2ePkEetx32"
      },
      "outputs": [],
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "    channel_loss = K.sum(K.square(y_pred - y_true), axis=-1)\n",
        "    total_loss = K.mean(channel_loss, axis=-1)\n",
        "    print(total_loss.shape)\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtgsLeFxtx32"
      },
      "outputs": [],
      "source": [
        "def create_callbacks(wts_fn, lr_decay = 0.25, patience=10, enable_save_wts = True):\n",
        "\n",
        "    cbks = []\n",
        "\n",
        "    # learning rate\n",
        "    '''lr_schedule = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                    factor=lr_decay,\n",
        "                                    patience=patience,\n",
        "                                    min_lr=1e-6,\n",
        "                                    verbose=1)\n",
        "    cbks.append(lr_schedule)'''\n",
        "\n",
        "    # early stopping\n",
        "    early_stopper = EarlyStopping(monitor='val_loss', patience=patience)\n",
        "    cbks.append(early_stopper)\n",
        "\n",
        "    # model checkpoint\n",
        "    if enable_save_wts is True:\n",
        "        model_chpt = ModelCheckpoint(filepath=wts_fn,\n",
        "                        monitor='val_loss',\n",
        "                        verbose=1,\n",
        "                        save_weights_only=True,\n",
        "                        save_best_only=False,\n",
        "                        save_freq=patience)\n",
        "\n",
        "        cbks.append(model_chpt)\n",
        "\n",
        "    return cbks\n",
        "\n",
        "\n",
        "'''def findLearningRate(model, model_name):\n",
        "\n",
        "    print(\"{}\".format(model_name))\n",
        "    lrs = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
        "\n",
        "    # find initial learning rate\n",
        "    for lr in lrs:\n",
        "        print(\"Learning Rate: {}\".format(lr))\n",
        "        optim = Adam(lr=lr)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=optim, metrics=None)\n",
        "        model.fit_generator(generator=train_gen,\n",
        "                            epochs=1)'''\n",
        "\n",
        "\n",
        "def trainModel(model, model_name, n_epochs, lr, load_saved_wts = False):\n",
        "\n",
        "    wts_fn = os.path.join(data_dir,model_name + \".weights.h5\")\n",
        "\n",
        "    if load_saved_wts is True:\n",
        "        model.load_weights(wts_fn)\n",
        "\n",
        "    # optim = RMSprop(learning_rate=lr)\n",
        "    optim = Adam(learning_rate=lr)\n",
        "    cbks = create_callbacks(wts_fn)\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=optim, metrics=None)\n",
        "    model.fit(train_gen,\n",
        "         validation_data=val_gen,\n",
        "         batch_size=4,\n",
        "         epochs=n_epochs,\n",
        "         callbacks=cbks)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjw2fqGqtx32"
      },
      "source": [
        "### Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha8RrBvXtx32"
      },
      "outputs": [],
      "source": [
        "loss_type = \"mse\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTsUlBLftx32"
      },
      "outputs": [],
      "source": [
        "unet = trainModel(unet, \"unet1\", n_epochs=100, lr=1e-3, load_saved_wts=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKtaHGPftx33"
      },
      "source": [
        "## Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scl0KTSLtx33"
      },
      "outputs": [],
      "source": [
        "def maskToKeypoints(mask):\n",
        "    kp = np.unravel_index(np.argmax(mask, axis=None), shape=(width,width))\n",
        "    return kp[1], kp[0]\n",
        "\n",
        "\n",
        "def calcKeypoints(model, gen):\n",
        "    kps_gt = []\n",
        "    kps_preds = []\n",
        "    nbatches = len(gen)\n",
        "\n",
        "    for i in range(nbatches):\n",
        "        # print(\"\\nBatch {}\".format(i))\n",
        "        imgs, batch_gt = gen[i]\n",
        "        batch_preds = model.predict(imgs)\n",
        "        print(batch_preds.shape)\n",
        "        n_imgs = imgs.shape[0]\n",
        "        for j in range(n_imgs):\n",
        "          mask_gt = batch_gt[j]\n",
        "          mask_gt = np.reshape(mask_gt, newshape=(width, width, num_kps))\n",
        "          mask_pred = batch_preds[j]\n",
        "          mask_pred = np.reshape(mask_pred, newshape=(width, width, num_kps))\n",
        "          nchannels = mask_gt.shape[-1]\n",
        "\n",
        "          gt_list = []\n",
        "          pred_list = []\n",
        "\n",
        "          for k in range(nchannels):\n",
        "              xgt, ygt = maskToKeypoints(mask_gt[:, :, k])\n",
        "              xpred, ypred = maskToKeypoints(mask_pred[:, :, k])\n",
        "\n",
        "              gt_list.append(xgt)\n",
        "              gt_list.append(ygt)\n",
        "\n",
        "              pred_list.append(xpred)\n",
        "              pred_list.append(ypred)\n",
        "\n",
        "          kps_gt.append(gt_list)\n",
        "          kps_preds.append(pred_list)\n",
        "\n",
        "\n",
        "\n",
        "    return np.array(kps_gt, dtype=np.float32), np.array(kps_preds, dtype=np.float32)\n",
        "\n",
        "\n",
        "def calcRMSError(kps_gt, kps_preds):\n",
        "\n",
        "    N = kps_gt.shape[0] * (kps_gt.shape[-1] // 2)\n",
        "    error = np.sqrt(np.sum((kps_gt-kps_preds)**2)/N)\n",
        "\n",
        "    return error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3iVdRp_tx33"
      },
      "source": [
        "### Visualize Keypoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M62-4-Mstx33"
      },
      "outputs": [],
      "source": [
        "def show_keypoints(batch_imgs, batch_labels, nrows, ncols, predictions=None):\n",
        "\n",
        "    def draw_keypoints(img, keypoints, col):\n",
        "        # print(\"\\n{}\".format(len(keypoints)))\n",
        "        for i in range(0, len(keypoints)-1, 2):\n",
        "            # print(i)\n",
        "            kpx = int(keypoints[i])\n",
        "            kpy = int(keypoints[i+1])\n",
        "            img = cv.circle(img, center=(kpx,kpy), radius=2, color=col, thickness=2)\n",
        "\n",
        "        return img\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(30, 30))\n",
        "\n",
        "    r = -1\n",
        "\n",
        "    for i in range(len(batch_imgs)):\n",
        "\n",
        "        img = batch_imgs[i]\n",
        "        img = np.reshape(img, newshape=(width, width))\n",
        "        img = np.stack([img,img,img], axis=-1)\n",
        "\n",
        "        c = i % ncols\n",
        "\n",
        "        if i % ncols == 0:\n",
        "            r += 1\n",
        "\n",
        "        # draw ground-truth keypoints on image\n",
        "        if batch_labels is not None:\n",
        "            img = draw_keypoints(img, batch_labels[i], col=(0,0,255))\n",
        "\n",
        "        # draw predicted keypoints on image\n",
        "        if predictions is not None:\n",
        "            img = draw_keypoints(img, predictions[i], col=(255,0,0))\n",
        "\n",
        "        axes[r, c].imshow(img)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX5_kNOBtx33"
      },
      "source": [
        "### Visualize All Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BohfE3xtx33"
      },
      "outputs": [],
      "source": [
        "def showAllMasks(width,img_mask, nrows=4, ncols=5):\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
        "\n",
        "    r = -1\n",
        "\n",
        "    for i in range(img_mask.shape[-1]):\n",
        "\n",
        "        img = img_mask[:, :, i]\n",
        "        # print(img.shape)\n",
        "        img = np.reshape(img, newshape=(width, width))\n",
        "        img = np.stack([img,img,img], axis=-1)\n",
        "\n",
        "        c = i % ncols\n",
        "\n",
        "        if i % ncols == 0:\n",
        "            r += 1\n",
        "\n",
        "        axes[r, c].imshow(img)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdsuCHoNtx33"
      },
      "source": [
        "### UNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U6fsdyjtx33"
      },
      "source": [
        "#### Qualitative Mask Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq7pB9q0tx33"
      },
      "outputs": [],
      "source": [
        "imgs, masks = val_gen[0]\n",
        "unet.load_weights(\"/content/drive/MyDrive/Dataset/facial-keypoints-detection/unet1.weights.h5\")\n",
        "preds = unet.predict_on_batch(imgs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s81bmTDbtx33"
      },
      "outputs": [],
      "source": [
        "print(masks.shape)\n",
        "print(preds.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSRkVGUitx33"
      },
      "outputs": [],
      "source": [
        "show_xray_masks(width, width, num_kps, imgs[0:3], masks[0:3], nrows=3, ncols=3, include_preds=True, predictions = preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1ZgwwIctx34"
      },
      "outputs": [],
      "source": [
        "gt_mask = masks[1]\n",
        "gt_mask = np.reshape(gt_mask, newshape=(width,width,num_kps))\n",
        "showAllMasks(width, gt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPcb9hM4tx34"
      },
      "outputs": [],
      "source": [
        "pred_mask = preds[1]\n",
        "pred_mask = np.reshape(pred_mask, newshape=(width,width,num_kps))\n",
        "showAllMasks(width, pred_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmyz6RVQtx34"
      },
      "source": [
        "#### Get keypoints from masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkfuE9Y5tx34"
      },
      "outputs": [],
      "source": [
        "kps_gt, kps_preds = calcKeypoints(unet, val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFdlNrqqtx34"
      },
      "outputs": [],
      "source": [
        "print(kps_preds.shape)\n",
        "print(kps_gt.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mubrg3t-tx34"
      },
      "source": [
        "#### Qualitative keypoint results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZzr0AhVtx34"
      },
      "outputs": [],
      "source": [
        "show_keypoints(imgs[0:8], kps_gt[0:8], nrows=2, ncols=4, predictions=kps_preds[0:8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dpkEtzCtx35"
      },
      "source": [
        "#### Calculate RMS Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9xG9eLJtx35"
      },
      "outputs": [],
      "source": [
        "rms_error = calcRMSError(kps_gt, kps_preds)\n",
        "print(\"Validation RMS Error = {}\".format(rms_error))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}